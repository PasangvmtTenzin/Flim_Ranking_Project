{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecasts(models, scalers, features, start_year, end_year, data):\n",
    "    forecast_data = []\n",
    "    \n",
    "    # Generate forecast years\n",
    "    forecast_years = range(start_year, end_year + 1)\n",
    "    \n",
    "    for year in forecast_years:\n",
    "        # Create dummy row for prediction (assuming missing data scenario)\n",
    "        dummy_data = pd.DataFrame({ # type: ignore\n",
    "            'Year': [year],\n",
    "            'total_votes': [data['total_votes'].mean()],\n",
    "            'GDP': [data['GDP'].mean()],\n",
    "            'Population': [data['Population'].mean()]\n",
    "        })\n",
    "        \n",
    "        dummy_row = pd.DataFrame([[year] + [0] * len(features)], columns=['Year'] + features) # type: ignore\n",
    "        \n",
    "        # Scale dummy row using the fitted scaler for each target\n",
    "        for target in models.keys():\n",
    "            scaler = scalers[target]\n",
    "            scaled_row = pd.DataFrame(scaler.transform(dummy_row[features]), columns=features) # type: ignore\n",
    "            \n",
    "            for model_name, model_info in models[target].items():\n",
    "                model = model_info['Model']\n",
    "                \n",
    "                # Predict using scaled dummy row\n",
    "                predicted_value = model.predict(scaled_row.values.reshape(1, -1))\n",
    "                \n",
    "                # Calculate CIS based on predicted_value and dummy_data\n",
    "                CIS = None\n",
    "                if not dummy_data.empty and not pd.isna(dummy_data['total_votes'].values[0]): # type: ignore\n",
    "                    CIS = predicted_value * dummy_data['total_votes'].values[0]\n",
    "                \n",
    "                # Prepare forecast entry\n",
    "                forecast_entry = {\n",
    "                    'Year': year,\n",
    "                    'Target': target,\n",
    "                    'Model': model_name,\n",
    "                    'CIS': CIS,\n",
    "                    'GDP_Normalized_CIS': CIS / dummy_data['GDP'].values[0] if CIS is not None else None,\n",
    "                    'Population_Normalized_CIS': CIS / dummy_data['Population'].values[0] if CIS is not None else None,\n",
    "                    'OIS': CIS,\n",
    "                    'strong_hegemony': predicted_value[0],\n",
    "                    'weak_hegemony': predicted_value[0],\n",
    "                    'Prediction': predicted_value[0]\n",
    "                }\n",
    "                \n",
    "                forecast_data.append(forecast_entry)\n",
    "    \n",
    "    forecast_data_df = pd.DataFrame(forecast_data) # type: ignore\n",
    "    return forecast_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_csv # type: ignore\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "\n",
    "# Function to clean data\n",
    "def clean_data(data):\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])\n",
    "    \n",
    "    # Remove duplicates based on Country_Name and Year\n",
    "    data = data.drop_duplicates(subset=['Country_Name', 'Year'])\n",
    "    \n",
    "    # Create additional features\n",
    "    data['CIS'] = data['average_quality_score'] * data['total_votes']\n",
    "    data['GDP_Normalized_CIS'] = data['CIS'] / data['GDP']\n",
    "    data['Population_Normalized_CIS'] = data['CIS'] / data['Population']\n",
    "    data['OIS'] = data['CIS']  # Assuming OIS is the same as CIS for now\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Define Features and Targets\n",
    "features = ['GDP', 'Population', 'CIS', 'GDP_Normalized_CIS', 'Population_Normalized_CIS']\n",
    "targets = ['OIS', 'strong_hegemony', 'weak_hegemony']\n",
    "\n",
    "# Function to train models\n",
    "def train_models(data, features, targets, params):\n",
    "    results_train = {}\n",
    "    scalers = {}\n",
    "\n",
    "    for target in targets:\n",
    "        X = data[features]\n",
    "        y = data[target]\n",
    "\n",
    "        # Standardize features using ColumnTransformer\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), features)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Fit the preprocessor on X\n",
    "        X_train = pd.DataFrame(preprocessor.fit_transform(X), columns=features)\n",
    "        \n",
    "        # Split data into training and test/validation sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Define models and parameters for GridSearchCV\n",
    "        models = {\n",
    "            'Linear Regression': {\n",
    "                'model': LinearRegression(),\n",
    "                'params': params.get('Linear Regression', {})\n",
    "            },\n",
    "            'Decision Tree': {\n",
    "                'model': DecisionTreeRegressor(),\n",
    "                'params': params.get('Decision Tree', {'regressor__max_depth': [5, 10, 15]})\n",
    "            },\n",
    "            'Gradient Boosting': {\n",
    "                'model': GradientBoostingRegressor(),\n",
    "                'params': params.get('Gradient Boosting', {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.1, 0.05]})\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'model': XGBRegressor(objective='reg:squarederror'),\n",
    "                'params': params.get('XGBoost', {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.1, 0.05]})\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        target_results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            # Create a pipeline with the preprocessor and the model\n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('regressor', model['model'])\n",
    "            ])\n",
    "            \n",
    "            # Perform GridSearchCV on the pipeline\n",
    "            grid_search = GridSearchCV(estimator=pipeline, param_grid=model['params'], \n",
    "                                       scoring='neg_root_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model from GridSearchCV\n",
    "            best_model = grid_search.best_estimator_\n",
    "            \n",
    "            # Cross-validation results on training data\n",
    "            cv_results = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "            cv_rmse_mean = np.mean(np.sqrt(-cv_results))\n",
    "            cv_rmse_std = np.std(np.sqrt(-cv_results))\n",
    "            \n",
    "            # Evaluate on test/validation data\n",
    "            y_pred_test = best_model.predict(X_test)\n",
    "            rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "            \n",
    "            # Save results for the best model\n",
    "            target_results[model_name] = {\n",
    "                'Model': best_model,\n",
    "                'CV_RMSE_Mean': cv_rmse_mean,\n",
    "                'CV_RMSE_Std': cv_rmse_std,\n",
    "                'RMSE': rmse_test\n",
    "            }\n",
    "        \n",
    "        results_train[target] = target_results\n",
    "        scalers[target] = preprocessor\n",
    "\n",
    "    return results_train, scalers\n",
    "\n",
    "# Function to plot model performance\n",
    "def plot_model_performance(results_train):\n",
    "    all_data = []\n",
    "    for target, target_results in results_train.items():\n",
    "        for model_name, metrics in target_results.items():\n",
    "            all_data.append({\n",
    "                'Target': target,\n",
    "                'Model': model_name,\n",
    "                'Metric': 'CV_RMSE_Mean',\n",
    "                'Value': metrics['CV_RMSE_Mean']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    fig = px.bar(df, x='Model', y='Value', color='Target', barmode='group', title='Model Performance by Target')\n",
    "    fig.update_layout(yaxis_type='log')\n",
    "    fig.write_html('plots_src/model_performance.html')\n",
    "\n",
    "# Function to make forecasts\n",
    "def make_forecasts(models_to_use, scalers, features, start_year, end_year, data):\n",
    "    forecasts = []\n",
    "    \n",
    "    # Generate years to forecast\n",
    "    years = list(range(start_year, end_year + 1))\n",
    "    \n",
    "    for year in years:\n",
    "        forecast_row = {}\n",
    "\n",
    "        for feature in features:\n",
    "            forecast_row[feature] = data[feature].mean()  # Replace with appropriate forecasting logic\n",
    "\n",
    "        # Create a dummy row DataFrame with forecast values\n",
    "        dummy_row = pd.DataFrame(forecast_row, index=[0])\n",
    "\n",
    "        for target, model in models_to_use.items():\n",
    "            preprocessor = scalers[target]  # Get the preprocessor (ColumnTransformer)\n",
    "            \n",
    "            # Transform the dummy row using the preprocessor\n",
    "            scaled_row = pd.DataFrame(preprocessor.transform(dummy_row[features]), columns=features)  # Ensure DataFrame\n",
    "            \n",
    "            # Predict using the model\n",
    "            predicted_value = model.predict(scaled_row.values.reshape(1, -1))\n",
    "            forecast_row[target] = predicted_value[0]  # Assuming single prediction output\n",
    "        \n",
    "        # Add year information\n",
    "        forecast_row['Year'] = year\n",
    "        \n",
    "        # Append forecast to forecasts list\n",
    "        forecasts.append(forecast_row)\n",
    "    \n",
    "    # Create DataFrame from forecasts list\n",
    "    forecast_data = pd.DataFrame(forecasts)\n",
    "    \n",
    "    return forecast_data\n",
    "\n",
    "# Function to plot forecasts over time\n",
    "def plot_forecasts(forecast_data):\n",
    "    fig = px.line(forecast_data, x='Year', y='Prediction', color='Target', line_dash='Model', title='Forecasts Over Time')\n",
    "    fig.write_html('plots_src/forecast_performance.html')\n",
    "\n",
    "# Function to plot combined performance (train and test/validation)\n",
    "def plot_combined_performance(results_train, results_test):\n",
    "    all_data = []\n",
    "    \n",
    "    # Append training (cross-validation) data\n",
    "    for target, target_results in results_train.items():\n",
    "        for model_name, metrics in target_results.items():\n",
    "            if 'CV_RMSE_Mean' in metrics:  # Using cross-validation RMSE mean for training\n",
    "                all_data.append({\n",
    "                    'Target': target,\n",
    "                    'Model': model_name,\n",
    "                    'Metric': 'CV_RMSE_Mean',\n",
    "                    'Value': metrics['CV_RMSE_Mean'],\n",
    "                    'Dataset': 'Training'\n",
    "                })\n",
    "    \n",
    "    # Append test/validation data\n",
    "    for target, target_results in results_test.items():\n",
    "        for model_name, metrics in target_results.items():\n",
    "            if 'RMSE' in metrics:  # Using RMSE for test/validation\n",
    "                all_data.append({\n",
    "                    'Target': target,\n",
    "                    'Model': model_name,\n",
    "                    'Metric': 'RMSE',\n",
    "                    'Value': metrics['RMSE'],\n",
    "                    'Dataset': 'Test/Validation'\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Plot combined performance\n",
    "    fig = px.bar(df, x='Model', y='Value', color='Target', barmode='group', facet_col='Dataset', title='Combined Model Performance')\n",
    "    fig.update_layout(yaxis_type='log')\n",
    "    fig.write_html('plots_src/combined_performance.html')\n",
    "\n",
    "# Function to save best models\n",
    "def save_best_model(results, model_path='src/'):\n",
    "    best_models = {}\n",
    "    for target, target_results in results.items():\n",
    "        best_model = min(target_results.items(), key=lambda x: x[1]['CV_RMSE_Mean'])  # Use CV_RMSE_Mean for finding best model\n",
    "        best_models[target] = best_model[1]['Model']\n",
    "        joblib.dump(best_model[1]['Model'], f\"{model_path}{target}.pkl\")\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    data = load_csv('../merged_data/final_data.csv')\n",
    "    \n",
    "    # Clean data\n",
    "    data = clean_data(data)\n",
    "    \n",
    "    # Ensure data has necessary columns for predictions\n",
    "    required_columns = ['Model', 'Best_OIS_Prediction', 'Best_strong_hegemony_Prediction', 'Best_weak_hegemony_Prediction']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            data[col] = None\n",
    "    \n",
    "    # Define Model Parameters\n",
    "    params = {\n",
    "        'Linear Regression': {},\n",
    "        'Decision Tree': {'regressor__max_depth': [5, 10, 15]},\n",
    "        'Gradient Boosting': {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.1, 0.05]},\n",
    "        'XGBoost': {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.1, 0.05]}\n",
    "    }\n",
    "    \n",
    "    # Train Models\n",
    "    results_train, scalers = train_models(data, features, targets, params)\n",
    "    \n",
    "    # Print Results (modified for CV results)\n",
    "    for target, target_results in results_train.items():\n",
    "        print(f\"\\nResults for {target}:\")\n",
    "        for model_name, result in target_results.items():\n",
    "            print(f\"{model_name}: CV_RMSE_Mean={result['CV_RMSE_Mean']}, CV_RMSE_Std={result['CV_RMSE_Std']}, RMSE={result['RMSE']}\")\n",
    "    \n",
    "    # Make Forecasts from 2022 to 2040\n",
    "    models_to_use = {target: {model_name: info for model_name, info in target_results.items()} for target, target_results in results_train.items()}\n",
    "    forecast_data = make_forecasts(models_to_use, scalers, features, 2022, 2040, data)\n",
    "    \n",
    "    # Save Forecast Data\n",
    "    forecast_data.to_csv('src/forecast_data.csv', index=False)\n",
    "    \n",
    "    # Update data with best predictions\n",
    "    for _, row in forecast_data.iterrows():\n",
    "        year, target, model, prediction = row['Year'], row['Target'], row['Model'], row['Prediction']\n",
    "        data.loc[(data['Year'] == year) & (data['Model'] == model), f'Best_{target}_Prediction'] = prediction\n",
    "    \n",
    "    # Save updated data\n",
    "    data.to_csv('src/updated_data.csv', index=False)\n",
    "    \n",
    "    # Plot Model Performance\n",
    "    plot_model_performance(results_train)\n",
    "\n",
    "    # Plot Forecasts Over Time\n",
    "    plot_forecasts(forecast_data)\n",
    "\n",
    "    # Evaluate on Test/Validation Set and Plot Combined Performance\n",
    "    results_test = {}\n",
    "    for target, target_results in results_train.items():\n",
    "        target_test_results = {}\n",
    "        for model_name, result in target_results.items():\n",
    "            # Use the same model trained on X_train for evaluation on X_test\n",
    "            model = result['Model']\n",
    "            \n",
    "            # Predict on X_test\n",
    "            X_test = scalers[target].transform(X_test)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            \n",
    "            # Calculate RMSE on y_test and y_pred_test\n",
    "            rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test)) # type: ignore\n",
    "            \n",
    "            target_test_results[model_name] = {\n",
    "                'Model': model,\n",
    "                'RMSE': rmse_test\n",
    "            }\n",
    "        results_test[target] = target_test_results\n",
    "    \n",
    "    # Plot Combined Performance\n",
    "    plot_combined_performance(results_train, results_test)\n",
    "    \n",
    "    # Save Best Models\n",
    "    save_best_model(results_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
